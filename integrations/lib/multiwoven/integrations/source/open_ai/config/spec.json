{
  "documentation_url": "https://docs.multiwoven.com/integrations/source/open-ai-endpoint",
  "stream_type": "user_defined",
  "connector_query_type": "ai_ml",
  "connection_specification": {
    "$schema": "http://json-schema.org/draft-07/schema#",
    "title": "Open AI Endpoint",
    "type": "object",
    "required": ["api_key", "request_format", "response_format"],
    "properties": {
      "api_key": {
        "type": "string",
        "multiwoven_secret": true,
        "title": "API Key",
        "order": 0
      },
      "is_stream": {
        "type": "boolean",
        "title": "Streaming Enabled",
        "description": "Enables data streaming for such as chat, when supported by the model. When true, messages and model data are processed in chunks for immediate delivery, enhancing responsiveness. Default is false, processing only after the entire response is received.",
        "default": false,
        "order": 1
      },
      "config": {
        "title": "",
        "type": "object",
        "properties": {
          "timeout": {
            "type": "string",
            "default": "30",
            "title": "HTTP Timeout",
            "description": "The maximum time, in seconds, to wait for a response from the server before the request is canceled.",
            "order": 0
          }
        },
        "order": 2
      },
      "request_format": {
        "title": "Request Format",
        "description": "Sample Request Format",
        "type": "string",
        "x-request-format": true,
        "order": 3
      },
      "response_format": {
        "title": "Response Format",
        "description": "Sample Response Format",
        "type": "string",
        "x-response-format": true,
        "order": 4
      }
    }
  }
}
